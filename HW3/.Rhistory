library('splines')        ## for 'bs'
library('scatterplot3d')  ## for 'scatterplot3d'
library('manipulate')     ## for 'manipulate'
library('beeswarm')
prostate <-
read.table(url(
'https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data'))
View(prostate)
?pairs
pairs(prostate)
## predict lcavol from lcp
## fit linear model with squared error loss
fit <- lm(lcavol ~ lcp, data=prostate)
View(fit)
fit[["residuals"]]
coef(fit)
residuals(fit)
plot(prostate$lcp, prostate$lcavol,
xlab='lcp', ylab='lcavol')
abline(fit)
nb <- as.integer(n + 1)
nb <- as.integer(10)
?quantile
?lm
?bs
lcp_knots <- quants(prostate$lcp, 1)
## use linear spline in lcp with 1 knots
quants <- function(x, n) {
nb <- as.integer(n + 1)
qs <- seq(1/nb, n/nb, 1/nb)
quantile(x, probs=qs)
}
lcp_knots <- quants(prostate$lcp, 1)
fit <- lm(lcavol ~ bs(lcp, knots=lcp_knots, degree=1), data=prostate)
summary(fit)
residuals(fit)
plot(prostate$lcp, prostate$lcavol,
xlab='lcp', ylab='lcavol')
?length.out
x_grid <- seq(min(prostate$lcp), max(prostate$lcp), length.out=100)
lines(x_grid, predict(fit, data.frame(lcp=x_grid)))
abline(v=lcp_knots, lty=3)
## consider two predictors
fit <- lm(lcavol ~ lcp + age, data=prostate)
summary(fit)
coef(fit)
manipulate({
s3d <- scatterplot3d(
x=prostate$lcp, y=prostate$age, z=prostate$lcavol,
xlab='lcp', ylab='age', zlab='lcavol',
color='blue', pch=19, angle=angle.slider)
# Add regression surface
s3d$contour3d(fit)
}, angle.slider=slider(0,90,55,'angle'))
fit <- lm(lcavol ~ lcp + age + lcp:age, data=prostate)
summary(fit)
coef(fit)
residuals(fit)
manipulate({
s3d <- scatterplot3d(
x=prostate$lcp, y=prostate$age, z=prostate$lcavol,
xlab='lcp', ylab='age', zlab='lcavol',
color='blue', pch=19, angle=angle.slider)
# Add regression surface
s3d$contour3d(fit)
}, angle.slider=slider(0,90,55,'angle'))
## two predictors with linear splines
lcp_knots <- quants(prostate$lcp, 1)
age_knots <- quants(prostate$age, 1)
fit <- lm(lcavol ~ bs(lcp, knots=lcp_knots, degree=1) +
bs(age, knots=age_knots, degree=1),
data=prostate)
summary(fit)
coef(fit)
manipulate({
s3d <- scatterplot3d(
x=prostate$lcp, y=prostate$age, z=prostate$lcavol,
xlab='lcp', ylab='age', zlab='lcavol',
color='blue', pch=19, angle=angle.slider)
# Add regression surface
s3d$contour3d(function(x, y) {
predict(fit, data.frame(lcp=x, age=y))
})
}, angle.slider=slider(0,90,55,'angle'))
coef(fit)
## two predictors with linear splines and interaction
lcp_knots <- quants(prostate$lcp, 1)
age_knots <- quants(prostate$age, 1)
fit <- lm(lcavol ~ bs(lcp, knots=lcp_knots, degree=1) *
bs(age, knots=age_knots, degree=1),
data=prostate)
summary(fit)
coef(fit)
manipulate({
s3d <- scatterplot3d(
x=prostate$lcp, y=prostate$age, z=prostate$lcavol,
xlab='lcp', ylab='age', zlab='lcavol',
color='blue', pch=19, angle=angle.slider)
# Add regression surface
s3d$contour3d(function(x, y) {
predict(fit, data.frame(lcp=x, age=y))
})
}, angle.slider=slider(0,90,55,'angle'))
## categorical (binary) predictor
table(prostate$svi)
prostate$svi <- as.factor(prostate$svi)
fit <- lm(lcavol ~ svi, data=prostate)
summary(fit)
coef(fit)
residuals(fit)
beeswarm(lcavol ~ svi, data=prostate,
xlab='svi', ylab='lcavol')
x_grid <- factor(c('0','1'), levels(prostate$svi))
points(x=x_grid,
y=predict(fit, data.frame(svi=x_grid)),
pch=4, col='red', cex=2, lwd=4)
## categorical (multiclass) predictor
table(prostate$gleason)
prostate$gleason <- as.factor(prostate$gleason)
fit <- lm(lcavol ~ gleason, data=prostate)
summary(fit)
coef(fit)
residuals(fit)
beeswarm(lcavol ~ gleason, data=prostate,
xlab='gleason', ylab='lcavol')
x_grid <- factor(levels(prostate$gleason),
levels(prostate$gleason))
points(x=x_grid,
y=predict(fit, data.frame(gleason=x_grid)),
pch=4, col='red', cex=2, lwd=4)
## categorical and quantitative predictor
fit <- lm(lcavol ~ gleason + age, data=prostate)
summary(fit)
coef(fit)
residuals(fit)
manipulate({
s3d <- scatterplot3d(
x=prostate$gleason, y=prostate$age, z=prostate$lcavol,
xlab='gleason', ylab='age', zlab='lcavol',
color='blue', pch=19, angle=angle.slider)
# Add regression surface
gleason_lev <- levels(prostate$gleason)
s3d$contour3d(function(x, y) {
predict(fit, data.frame(
gleason=factor(gleason_lev[x], gleason_lev), age=y))
})
}, angle.slider=slider(0,90,55,'angle'))
coef(fit)
library('splines')        ## for 'bs'
library('dplyr')          ## for 'select', 'filter', and others
library('magrittr')       ## for '%<>%' operator
library('glmnet')         ## for 'glmnet'
prostate_train <- prostate %>%
filter(train == TRUE) %>%
select(-train)
View(prostate_train)
View(prostate)
## use glmnet to fit lasso
## glmnet fits using penalized L2 loss
## first create an input matrix and output vector
form  <- lcavol ~  lweight + age + lbph + lcp + pgg45 + lpsa + svi + gleason
x_inp <- model.matrix(form, data=prostate_train)
y_out <- prostate_train$lcavol
fit <- glmnet(x=x_inp, y=y_out, lambda=seq(0.5, 0, -0.05))
print(fit$beta)
View(fit)
summary(fit)
## functions to compute testing/training error with glmnet
error <- function(dat, fit, lam, form, loss=L2_loss) {
x_inp <- model.matrix(form, data=dat)
y_out <- dat$lcavol
y_hat <- predict(fit, newx=x_inp, s=lam)  ## see predict.elnet
mean(loss(y_out, y_hat))
}
## train_error at lambda=0
error(prostate_train, fit, lam=0, form=form)
## functions to compute testing/training error w/lm
L2_loss <- function(y, yhat)
(y-yhat)^2
error <- function(dat, fit, loss=L2_loss)
mean(loss(dat$lcavol, predict(fit, newdata=dat)))
## functions to compute testing/training error with glmnet
error <- function(dat, fit, lam, form, loss=L2_loss) {
x_inp <- model.matrix(form, data=dat)
y_out <- dat$lcavol
y_hat <- predict(fit, newx=x_inp, s=lam)  ## see predict.elnet
mean(loss(y_out, y_hat))
}
## train_error at lambda=0
error(prostate_train, fit, lam=0, form=form)
## testing error at lambda=0
error(prostate_test, fit, lam=0, form=form)
## split prostate into testing and training subsets
prostate_train <- prostate %>%
filter(train == TRUE) %>%
select(-train)
summary(prostate_train)
prostate_test <- prostate %>%
filter(train == FALSE) %>%
select(-train)
## functions to compute testing/training error with glmnet
error <- function(dat, fit, lam, form, loss=L2_loss) {
x_inp <- model.matrix(form, data=dat)
y_out <- dat$lcavol
y_hat <- predict(fit, newx=x_inp, s=lam)  ## see predict.elnet
mean(loss(y_out, y_hat))
}
## train_error at lambda=0
error(prostate_train, fit, lam=0, form=form)
## testing error at lambda=0
error(prostate_test, fit, lam=0, form=form)
## train_error at lambda=0.03
error(prostate_train, fit, lam=0.05, form=form)
## testing error at lambda=0.03
error(prostate_test, fit, lam=0.05, form=form)
## plot path diagram
plot(x=range(fit$lambda),
y=range(as.matrix(fit$beta)),
type='n',
xlab=expression(lambda),
ylab='Coefficients')
for(i in 1:nrow(fit$beta)) {
points(x=fit$lambda, y=fit$beta[i,], pch=19, col='#00000055')
lines(x=fit$lambda, y=fit$beta[i,], col='#00000055')
}
text(x=0, y=fit$beta[,ncol(fit$beta)],
labels=rownames(fit$beta),
xpd=NA, pos=4, srt=45)
abline(h=0, lty=3, lwd=2)
## compute training and testing errors as function of lambda
err_train_1 <- sapply(fit$lambda, function(lam)
error(prostate_train, fit, lam, form))
err_test_1 <- sapply(fit$lambda, function(lam)
error(prostate_test, fit, lam, form))
## plot test/train error
plot(x=range(fit$lambda),
y=range(c(err_train_1, err_test_1)),
xlim=rev(range(fit$lambda)),
type='n',
xlab=expression(lambda),
ylab='train/test error')
points(fit$lambda, err_train_1, pch=19, type='b', col='darkblue')
points(fit$lambda, err_test_1, pch=19, type='b', col='darkred')
legend('topright', c('train','test'), lty=1, pch=19,
col=c('darkblue','darkred'), bty='n')
colnames(fit$beta) <- paste('lam =', fit$lambda)
print(fit$beta %>% as.matrix)
## use lasso in combination with linear splines for
## lweight, age, lpbh, lcp, pgg45, and lpsa
## use linear splines with 2 knots
quants <- function(x, n) {
nb <- as.integer(n + 1)
qs <- seq(1/nb, n/nb, 1/nb)
quantile(x, probs=qs)
}
lweight_knots <- quants(prostate_train$lweight, 2)
age_knots     <- quants(prostate_train$age, 2)
lbph_knots    <- quants(prostate_train$lbph, 2)
lcp_knots     <- quants(prostate_train$lcp, 2)
pgg45_knots   <- quants(prostate_train$pgg45, 2)
lpsa_knots    <- quants(prostate_train$lpsa, 2)
form  <- lcavol ~     bs(lweight, knots=lweight_knots, degree=1, ) +
bs(age, knots=age_knots, degree=1) +
bs(lbph, knots=lbph_knots, degree=1) +
bs(lcp, knots=lcp_knots, degree=1) +
bs(pgg45, knots=pgg45_knots, degree=1) +
bs(lpsa, knots=lpsa_knots, degree=1) +
svi + gleason
x_inp <- model.matrix(form, data=prostate_train)
y_out <- prostate_train$lcavol
fit <- glmnet(x=x_inp, y=y_out, lambda=seq(0.5, 0, -0.05))
## plot path diagram
plot(x=range(fit$lambda),
y=range(as.matrix(fit$beta)),
type='n',
xlab=expression(lambda),
ylab='Coefficients')
for(i in 1:nrow(fit$beta)) {
points(x=fit$lambda, y=fit$beta[i,], pch=19, col='#00000055')
lines(x=fit$lambda, y=fit$beta[i,], col='#00000055')
}
abline(h=0, lty=3, lwd=2)
## compute training and testing errors as function of lambda
err_train_2 <- sapply(fit$lambda, function(lam)
error(prostate_train, fit, lam, form))
err_test_2 <- sapply(fit$lambda, function(lam)
error(prostate_test, fit, lam, form))
## plot test error for model with and and without linear splines
plot(x=range(fit$lambda),
y=range(c(err_test_1, err_test_2)),
xlim=rev(range(fit$lambda)),
type='n',
xlab=expression(lambda),
ylab='test error')
points(seq(0.5, 0, -0.05), err_test_1, pch=19, type='b', col='darkblue')
points(fit$lambda, err_test_2, pch=19, type='b', col='darkred')
legend('top', c('no splines','linear splines'), lty=1, pch=19,
col=c('darkblue','darkred'), bty='n')
colnames(fit$beta) <- paste('lam =', fit$lambda)
View(fit$beta %>% as.matrix)
library('splines')        ## for 'bs'
library('dplyr')          ## for 'select', 'filter', and others
library('magrittr')       ## for '%<>%' operator
library('glmnet')         ## for 'glmnet'
prostate <-
read.table(url(
'https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data'))
prostate_train <- prostate %>%
filter(train == TRUE) %>%
select(-train)
prostate_test <- prostate %>%
filter(train == FALSE) %>%
select(-train)
?cor
C = cor(prostate)
(C = cor(prostate))
symnum(C = cor(prostate))
symnum(cor(prostate)
symnum(cor(prostate))
(cor(prostate))
